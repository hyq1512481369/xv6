diff --git a/Makefile b/Makefile
index ce1e043..6aacc0f 100644
--- a/Makefile
+++ b/Makefile
@@ -180,6 +180,8 @@ UPROGS=\
 	$U/_grind\
 	$U/_wc\
 	$U/_zombie\
+	$U/_usertests\
+	$U/_kalloctest\
 
 
 
diff --git a/kernel/bio.c b/kernel/bio.c
index 60d91a6..6857db2 100644
--- a/kernel/bio.c
+++ b/kernel/bio.c
@@ -23,33 +23,48 @@
 #include "fs.h"
 #include "buf.h"
 
+#define NBUCKETS 13
+struct hashbucket{
+  struct buf head;
+};
+
+
 struct {
-  struct spinlock lock;
+  struct spinlock bucket_lock[NBUCKETS];
+  struct spinlock main_lock;
   struct buf buf[NBUF];
 
   // Linked list of all buffers, through prev/next.
   // Sorted by how recently the buffer was used.
   // head.next is most recent, head.prev is least.
-  struct buf head;
+  struct hashbucket buckets[NBUCKETS];
 } bcache;
 
+static char lock_name[NBUCKETS][9];
 void
 binit(void)
 {
   struct buf *b;
-
-  initlock(&bcache.lock, "bcache");
-
-  // Create linked list of buffers
-  bcache.head.prev = &bcache.head;
-  bcache.head.next = &bcache.head;
-  for(b = bcache.buf; b < bcache.buf+NBUF; b++){
-    b->next = bcache.head.next;
-    b->prev = &bcache.head;
-    initsleeplock(&b->lock, "buffer");
-    bcache.head.next->prev = b;
-    bcache.head.next = b;
+ 
+  initlock(&bcache.main_lock, "main_lock");
+  for(int i=0;i<NBUCKETS;i++){
+    strncpy(lock_name[i],"bcacheN\0\0",8);
+    if(i<10)lock_name[i][6]='0'+i;
+    else {lock_name[i][6]='1';lock_name[i][7]=i-10+'0';}
+    initlock(&(bcache.bucket_lock[i]),lock_name[i]);
+    // Create linked list of buffers
+    bcache.buckets[i].head.prev =  &bcache.buckets[i].head;
+    bcache.buckets[i].head.next =  &bcache.buckets[i].head;
   }
+    for(b = bcache.buf; b < bcache.buf+NBUF; b++){
+      int hash=(b-bcache.buf)%NBUCKETS;
+      b->next = bcache.buckets[hash].head.next;
+      b->prev = &bcache.buckets[hash].head;
+      initsleeplock(&b->lock, "buffer");
+      bcache.buckets[hash].head.next->prev = b;
+      bcache.buckets[hash].head.next = b;
+    }
+  
 }
 
 // Look through buffer cache for block on device dev.
@@ -59,31 +74,83 @@ static struct buf*
 bget(uint dev, uint blockno)
 {
   struct buf *b;
-
-  acquire(&bcache.lock);
+  int hash=blockno%NBUCKETS;
+  acquire(&bcache.bucket_lock[hash]);
 
   // Is the block already cached?
-  for(b = bcache.head.next; b != &bcache.head; b = b->next){
+  for(b = bcache.buckets[hash].head.next; b != &bcache.buckets[hash].head; b = b->next){
+    
     if(b->dev == dev && b->blockno == blockno){
       b->refcnt++;
-      release(&bcache.lock);
+      release(&bcache.bucket_lock[hash]);
+      acquiresleep(&b->lock);
+      return b;
+    }
+  }
+   for(b = bcache.buckets[hash].head.next; b != &bcache.buckets[hash].head; b = b->next){
+    
+    if(b->refcnt==0){
+        b->dev = dev; 
+        b->blockno = blockno;
+        b->valid = 0;
+        b->refcnt = 1;
+      release(&bcache.bucket_lock[hash]);
       acquiresleep(&b->lock);
       return b;
     }
   }
 
+ release(&bcache.bucket_lock[hash]);
   // Not cached.
   // Recycle the least recently used (LRU) unused buffer.
-  for(b = bcache.head.prev; b != &bcache.head; b = b->prev){
-    if(b->refcnt == 0) {
-      b->dev = dev;
-      b->blockno = blockno;
-      b->valid = 0;
-      b->refcnt = 1;
-      release(&bcache.lock);
+  acquire(&bcache.main_lock);
+  acquire(&bcache.bucket_lock[hash]);
+  for(b = bcache.buckets[hash].head.next; b != &bcache.buckets[hash].head; b = b->next){
+    if(b->dev == dev && b->blockno == blockno){
+      b->refcnt++;
+      release(&bcache.bucket_lock[hash]);
+      release(&bcache.main_lock);
       acquiresleep(&b->lock);
       return b;
     }
+  }
+   for(b = bcache.buckets[hash].head.next; b != &bcache.buckets[hash].head; b = b->next){
+    if(b->refcnt==0){
+        b->dev = dev; 
+        b->blockno = blockno;
+        b->valid = 0;
+        b->refcnt = 1;
+      release(&bcache.bucket_lock[hash]);
+      release(&bcache.main_lock);
+      acquiresleep(&b->lock);
+      return b;
+    }
+  }
+  for(int k=hash+1;k<hash+NBUCKETS;k++){
+    int temp=k%NBUCKETS;
+    acquire(&bcache.bucket_lock[temp]);
+    for(b = bcache.buckets[temp].head.prev; b != &bcache.buckets[temp].head; b = b->prev){
+      
+      
+      if(b->refcnt == 0) {
+        b->dev = dev; 
+        b->blockno = blockno;
+        b->valid = 0;
+        b->refcnt = 1;
+        b->prev->next=b->next;
+        b->next->prev=b->prev;
+        b->next=bcache.buckets[hash].head.next;
+        b->prev=b->next->prev;
+        b->prev->next=b;
+        b->next->prev=b;
+        if(hash!=temp)release(&bcache.bucket_lock[temp]);
+        release(&bcache.bucket_lock[hash]);
+        release(&bcache.main_lock);
+        acquiresleep(&b->lock);
+        return b;
+      }
+    }
+    release(&bcache.bucket_lock[temp]);
   }
   panic("bget: no buffers");
 }
@@ -118,36 +185,39 @@ brelse(struct buf *b)
 {
   if(!holdingsleep(&b->lock))
     panic("brelse");
-
+  
   releasesleep(&b->lock);
 
-  acquire(&bcache.lock);
+  int hash=b->blockno%NBUCKETS;
+  acquire(&bcache.bucket_lock[hash]);
   b->refcnt--;
   if (b->refcnt == 0) {
     // no one is waiting for it.
     b->next->prev = b->prev;
     b->prev->next = b->next;
-    b->next = bcache.head.next;
-    b->prev = &bcache.head;
-    bcache.head.next->prev = b;
-    bcache.head.next = b;
+    b->next = bcache.buckets[hash].head.next;
+    b->prev = &bcache.buckets[hash].head;
+    bcache.buckets[hash].head.next->prev = b;
+    bcache.buckets[hash].head.next = b;
   }
   
-  release(&bcache.lock);
+  release(&bcache.bucket_lock[hash]);
 }
 
 void
 bpin(struct buf *b) {
-  acquire(&bcache.lock);
+  int hash=b->blockno%NBUCKETS;
+  acquire(&bcache.bucket_lock[hash]);
   b->refcnt++;
-  release(&bcache.lock);
+  release(&bcache.bucket_lock[hash]);
 }
 
 void
 bunpin(struct buf *b) {
-  acquire(&bcache.lock);
+   int hash=b->blockno%NBUCKETS;
+  acquire(&bcache.bucket_lock[hash]);
   b->refcnt--;
-  release(&bcache.lock);
+  release(&bcache.bucket_lock[hash]);
 }
 
 
diff --git a/kernel/kalloc.c b/kernel/kalloc.c
index fa6a0ac..044be1c 100644
--- a/kernel/kalloc.c
+++ b/kernel/kalloc.c
@@ -18,16 +18,25 @@ struct run {
   struct run *next;
 };
 
-struct {
+struct kmem{
   struct spinlock lock;
   struct run *freelist;
-} kmem;
+};
+struct kmem kmems[NCPU];
+
 
 void
 kinit()
-{
-  initlock(&kmem.lock, "kmem");
-  freerange(end, (void*)PHYSTOP);
+{static char name[NCPU][6]={};
+   
+  for(int i=0;i<NCPU;i++)
+    { strncpy(name[i],"kmemN",6);
+      *(name[i]+4)=(char)(i+'0');
+      initlock(&(kmems[i].lock), name[i]);
+    }
+ 
+    freerange(end, (void*)PHYSTOP);
+    
 }
 
 void
@@ -55,11 +64,15 @@ kfree(void *pa)
   memset(pa, 1, PGSIZE);
 
   r = (struct run*)pa;
+  push_off();
+  int cpu_id=cpuid();
+  acquire(&(kmems[cpu_id].lock));
 
-  acquire(&kmem.lock);
-  r->next = kmem.freelist;
-  kmem.freelist = r;
-  release(&kmem.lock);
+  r->next = kmems[cpu_id].freelist;
+  kmems[cpu_id].freelist = r;
+
+  release(&(kmems[cpu_id].lock));
+  pop_off();
 }
 
 // Allocate one 4096-byte page of physical memory.
@@ -69,13 +82,28 @@ void *
 kalloc(void)
 {
   struct run *r;
-
-  acquire(&kmem.lock);
-  r = kmem.freelist;
+  push_off();
+  int cpu_id=cpuid();
+  acquire(&(kmems[cpu_id].lock));
+  r = kmems[cpu_id].freelist;
   if(r)
-    kmem.freelist = r->next;
-  release(&kmem.lock);
-
+    kmems[cpu_id].freelist = r->next;
+  else{
+    for(int i=0;i<NCPU;i++){
+      if(i==cpu_id) continue;
+      acquire(&(kmems[i].lock));
+      int flag=0;
+      r=kmems[i].freelist;
+      if(r){
+        kmems[i].freelist=r->next;
+        flag=1;
+      }
+       release(&(kmems[i].lock));
+       if(flag) break;
+    }
+  }
+  release(&(kmems[cpu_id].lock));
+  pop_off();
   if(r)
     memset((char*)r, 5, PGSIZE); // fill with junk
   return (void*)r;
diff --git a/time.txt b/time.txt
new file mode 100644
index 0000000..301160a
--- /dev/null
+++ b/time.txt
@@ -0,0 +1 @@
+8
\ No newline at end of file
